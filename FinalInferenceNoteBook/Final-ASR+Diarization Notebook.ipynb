{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# First Install the dependencies and required libraries & FIles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "ulSwB5SIPKnw",
        "outputId": "c0c6ff6c-c19e-41b3-a725-ea7e0bdbe90f"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install wget\n",
        "!apt-get install sox libsndfile1 ffmpeg\n",
        "!pip install text-unidecode\n",
        "!pip install matplotlib>=3.3.2\n",
        "\n",
        "## Install NeMo\n",
        "BRANCH = 'r2.0.0rc0'\n",
        "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\n",
        "\n",
        "## Grab the config we'll use in this example\n",
        "!mkdir configs\n",
        "!wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/asr/conf/citrinet/config_bpe.yaml\n",
        "\n",
        "\"\"\"\n",
        "Remember to restart the runtime for the kernel to pick up any upgraded packages (e.g. matplotlib)!\n",
        "Alternatively, you can uncomment the exit() below to crash and restart the kernel, in the case\n",
        "that you want to use the \"Run All Cells\" (or similar) option.\n",
        "\"\"\"\n",
        "# exit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5BmbSFoJP2LJ",
        "outputId": "91c97b81-6bd2-4ec7-8675-a4b8e8a33d6d"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/7egment/pyannote-3.1-offline\n",
        "!pip install pyannote-audio==3.1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# We will edit the path on config file to work offline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qfSqKnstRzQq"
      },
      "outputs": [],
      "source": [
        "# Update the paths in the configuration file\n",
        "!sed -i 's|/home/e6quisitory/pyannote-3.1-offline/seg.bin|pyannote-3.1-offline/seg.bin|g' /content/pyannote-3.1-offline/config.yaml\n",
        "!sed -i 's|/home/e6quisitory/pyannote-3.1-offline/vox.bin|pyannote-3.1-offline/vox.bin|g' /content/pyannote-3.1-offline/config.yaml\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_cKnrVe3Phxc"
      },
      "outputs": [],
      "source": [
        "# NeMo's \"core\" package\n",
        "import nemo\n",
        "# NeMo's ASR collection - this collections contains complete ASR models and\n",
        "# building blocks (modules) for ASR\n",
        "import nemo.collections.asr as nemo_asr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FInally Inference Script , Dont Forget to add MetanoiaLabsModel from ``\\FinalinferenceNotebook`` directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4cDbB-MCS3TI",
        "outputId": "67ab4b86-a94f-4335-e7ee-3813c41a1d90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2024-07-22 21:29:31 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "      torchaudio.set_audio_backend(\"soundfile\")\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2024-07-22 21:29:34 mixins:172] Tokenizer SentencePieceTokenizer initialized with 64 tokens\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2024-07-22 21:29:34 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /content/Last_Hope.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    trim_silence: true\n",
            "    max_duration: 16.7\n",
            "    shuffle: true\n",
            "    num_workers: 8\n",
            "    pin_memory: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    shard_strategy: scatter\n",
            "    shuffle_n: 2048\n",
            "    bucketing_strategy: synced_randomized\n",
            "    bucketing_batch_size: null\n",
            "    \n",
            "[NeMo W 2024-07-22 21:29:34 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /content/Last_Hope.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    num_workers: 8\n",
            "    pin_memory: true\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2024-07-22 21:29:34 features:305] PADDING: 16\n",
            "[NeMo I 2024-07-22 21:29:35 save_restore_connector:263] Model EncDecCTCModelBPE was successfully restored from /content/MetanoiaLabsModel.nemo.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n",
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 29.79it/s]\n",
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s]\n",
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 34.05it/s]\n",
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 39.04it/s]\n",
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 33.64it/s]\n",
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 34.13it/s]\n",
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 23.50it/s]\n",
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 20.92it/s]\n",
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 24.10it/s]\n",
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 28.80it/s]\n",
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 36.94it/s]\n",
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 28.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed and saved ./Finaljsonfiles/audio_sample_12.json\n",
            "All files processed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from nemo.collections.asr.models import EncDecCTCModelBPE\n",
        "from pyannote.audio import Pipeline\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Initialize the ASR model\n",
        "asr_model = EncDecCTCModelBPE.restore_from(restore_path=\"/content/MetanoiaLabsModel.nemo\")\n",
        "\n",
        "# Initialize the diarization pipeline\n",
        "pipeline = Pipeline.from_pretrained(\"pyannote-3.1-offline/config.yaml\")\n",
        "\n",
        "# Directory containing WAV files\n",
        "audio_dir = \"./\"      # <-----------------------  Put wav Folder Here\n",
        "\n",
        "# Directory to save the JSON files\n",
        "output_dir = \"./Finaljsonfiles\"\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# List all WAV files in the directory\n",
        "audio_files = [os.path.join(audio_dir, f) for f in os.listdir(audio_dir) if f.endswith('.wav')]\n",
        "\n",
        "# Function to transcribe a segment\n",
        "def transcribe_segment(segment_audio):\n",
        "    return asr_model.transcribe([segment_audio], batch_size=1)[0]\n",
        "\n",
        "# Function to handle audio segment extraction and transcription\n",
        "def process_audio_file(audio_file):\n",
        "    audio_id = os.path.basename(audio_file).split('.')[0]\n",
        "    json_output = []\n",
        "\n",
        "    try:\n",
        "        # Load the audio file using pydub\n",
        "        audio = AudioSegment.from_wav(audio_file)\n",
        "\n",
        "        # Diarize the audio file\n",
        "        diarization = pipeline(audio_file)\n",
        "\n",
        "        # Extract and transcribe each segment\n",
        "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "            start_time = turn.start\n",
        "            end_time = turn.end\n",
        "\n",
        "            # Check if the segment duration is valid\n",
        "            if end_time <= start_time:\n",
        "                print(f\"Skipping invalid segment from {start_time} to {end_time} in {audio_file}\")\n",
        "                continue\n",
        "\n",
        "            # Extract the audio segment using pydub\n",
        "            segment_audio = audio[start_time * 1000:end_time * 1000]  # pydub works in milliseconds\n",
        "\n",
        "            # Transcribe the audio segment\n",
        "            # Save segment to a temporary file\n",
        "            segment_path = f\"{audio_id}_segment_{start_time:.3f}_{end_time:.3f}.wav\"\n",
        "            segment_audio.export(segment_path, format=\"wav\")\n",
        "\n",
        "            try:\n",
        "                text = transcribe_segment(segment_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Transcription failed for segment {segment_path}: {e}\")\n",
        "                text = \"\"\n",
        "\n",
        "            # Append the transcription to the JSON output\n",
        "            json_output.append({\n",
        "                \"start\": start_time,\n",
        "                \"end\": end_time,\n",
        "                \"speaker\": speaker,\n",
        "                \"text\": text\n",
        "            })\n",
        "\n",
        "            # Clean up the segment audio file\n",
        "            os.remove(segment_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_file}: {e}\")\n",
        "\n",
        "    # Save the JSON output to a file\n",
        "    json_file = os.path.join(output_dir, f\"{audio_id}.json\")\n",
        "    with open(json_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(json_output, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"Processed and saved {json_file}\")\n",
        "\n",
        "# Process each audio file\n",
        "for audio_file in audio_files:\n",
        "    process_audio_file(audio_file)\n",
        "\n",
        "print(\"All files processed.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
